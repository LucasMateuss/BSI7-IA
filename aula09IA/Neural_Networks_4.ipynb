{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjeZurop3Xzt",
        "outputId": "eff4d24d-2432-49c0-93e5-58898d81cec7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybIlkwkv3Q1E",
        "outputId": "720964c3-d6f9-47c1-958e-2a6dd1bf6b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   <p>One ring to rule them all, one ring to find them, One ring to bring them all and in the darkness    bind them.!!</p>   \n"
          ]
        }
      ],
      "source": [
        "raw_text = \"   <p>One ring to rule them all, one ring to find them, One ring to bring them all and in the darkness    bind them.!!</p>   \"\n",
        "print(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = raw_text.lower()\n",
        "\n",
        "text = text.strip()\n",
        "\n",
        "text = re.compile('<.*?>').sub('', text)\n",
        "\n",
        "text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
        "\n",
        "text = re.sub('\\\\s+', ' ', text)\n",
        "\n",
        "cleaned_text = text\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXLwf8Oo3a9H",
        "outputId": "30938851-e627-4a8f-89a2-1382e5d23ef1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one ring to rule them all one ring to find them one ring to bring them all and in the darkness bind them \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "words = word_tokenize(cleaned_text)\n",
        "\n",
        "filtered_sentence = []\n",
        "for w in words:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "text_without_stopwords = \" \".join(filtered_sentence)\n",
        "print(f\"Tokens originais: {words}\\n\")\n",
        "print(f\"Texto sem stopwords: \\n'{text_without_stopwords}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrjloeid3rTO",
        "outputId": "398d2e15-ad98-41e8-8912-b8067340d224"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens originais: ['one', 'ring', 'to', 'rule', 'them', 'all', 'one', 'ring', 'to', 'find', 'them', 'one', 'ring', 'to', 'bring', 'them', 'all', 'and', 'in', 'the', 'darkness', 'bind', 'them']\n",
            "\n",
            "Texto sem stopwords: \n",
            "'one ring rule one ring find one ring bring darkness bind'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "stemmed_sentence = []\n",
        "\n",
        "# Reutilizamos os tokens já sem as stopwords\n",
        "words_to_process = word_tokenize(text_without_stopwords)\n",
        "\n",
        "for w in words_to_process:\n",
        "    stemmed_sentence.append(porter.stem(w))\n",
        "\n",
        "stemmed_text = \" \".join(stemmed_sentence)\n",
        "print(f\"Texto após stemming:\\n'{stemmed_text}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ZhU2lM4hsT",
        "outputId": "4a8ea969-3f12-4ceb-9d5a-9b7805d8b818"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto após stemming:\n",
            "'one ring rule one ring find one ring bring dark bind'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "wl = WordNetLemmatizer()\n",
        "lemmatized_sentence = []\n",
        "\n",
        "# Reutilizamos os tokens já sem as stopwords\n",
        "words_to_process = word_tokenize(text_without_stopwords)\n",
        "word_pos_tags = nltk.pos_tag(words_to_process)\n",
        "\n",
        "for idx, tag in enumerate(word_pos_tags):\n",
        "    lemmatized_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
        "\n",
        "lemmatized_text = \" \".join(lemmatized_sentence)\n",
        "print(f\"Texto após lematização:\\n'{lemmatized_text}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtpVMCZC4k06",
        "outputId": "6fc67a53-e788-4e37-ac37-483f3a14725b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto após lematização:\n",
            "'one ring rule one ring find one ring bring darkness bind'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise Final: Stemming vs. Lemmatização (Item 6)\n",
        "\n",
        "**1. Comparação dos Resultados**\n",
        "\n",
        "Observando os resultados gerados pelo código, temos:\n",
        "* **Texto após Stemming:** `'one ring rule one ring find one ring bring dark bind'`\n",
        "* **Texto após Lematização:** `'one ring rule one ring find one ring bring darkness bind'`\n",
        "\n",
        "A diferença principal está na palavra **\"darkness\"**. O processo de *Stemming* a reduziu para `\"dark\"`, enquanto a *Lematização* a manteve intacta, pois reconheceu \"darkness\" como um substantivo válido.\n",
        "\n",
        "**2. Quando Usar Cada Técnica**\n",
        "\n",
        "* **Use Stemming quando:**\n",
        "    * A **velocidade** é a prioridade e a precisão gramatical não é crítica.\n",
        "    * **Exemplo:** Indexação de documentos para um motor de busca, onde o objetivo é agrupar rapidamente palavras com a mesma raiz.\n",
        "\n",
        "* **Use Lematização quando:**\n",
        "    * A **precisão** e o significado do texto são fundamentais.\n",
        "    * **Exemplo:** Análise de sentimento, chatbots ou tradução automática, onde o entendimento correto do contexto é crucial."
      ],
      "metadata": {
        "id": "iWnbxI2r7Pus"
      }
    }
  ]
}